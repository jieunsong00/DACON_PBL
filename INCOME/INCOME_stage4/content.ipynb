{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#hiddencell\n",
        "%pip install seaborn \n",
        "\n",
        "from pbl_tools import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "fe = fm.FontEntry(fname = 'MaruBuri-Regular.otf', name = 'MaruBuri')\n",
        "fm.fontManager.ttflist.insert(0, fe)\n",
        "plt.rc('font', family='MaruBuri')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 스테이지 4. 데이터 전처리 및 기본 모델 학습과 평가\n",
        "## 도입\n",
        "이번 스테이지에서는 데이터 전처리와 기본 모델 학습 및 평가에 중점을 둡니다. 이전 스테이지에서는 데이터의 구조와 상호 작용에 대한 이해를 높였으며, 이제는 실제 모델 학습을 위한 데이터 준비와 전처리 과정을 다룰 것입니다.\n",
        "\n",
        "데이터 전처리는 모델 학습의 핵심 단계 중 하나로, 데이터의 품질을 향상시키고 모델의 성능을 향상시키는 데 중요한 역할을 합니다. 여기서는 pandas를 사용하여 데이터를 읽어오고, 결측값을 처리하며, 범주형 데이터를 인코딩하는 방법을 배울 것입니다.\n",
        "\n",
        "또한 기본 모델인 RandomForestClassifier를 활용하여 데이터를 학습하고, 모델의 성능을 검증 데이터를 통해 평가할 것입니다. 이를 통해 모델의 초기 성능을 확인하고 개선 방향을 찾을 것입니다.\n",
        "\n",
        "마지막으로, 데이터 전처리를 개선하고 RandomForest 모델을 활용하여 데이터의 특성 중요도를 분석하는 방법을 배울 것입니다.\n",
        "\n",
        "## 학습 목표\n",
        "- 데이터를 훈련 세트와 검증 세트로 나누기 위해 train_test_split 함수를 활용하는 방법을 이해한다.\n",
        "- 범주형 데이터를 LabelEncoder를 이용하여 인코딩하는 방법을 익힌다.\n",
        "- randomForestClassifier 모델을 활용하여 검증 데이터에 대한 예측을 수행하고 모델 성능을 평가할 수 있다.\n",
        "- Macro F1 스코어를 계산하고 결과를 출력할 수 있다.\n",
        "- 결측값 처리에 Imputer를 적절히 활용할 수 있다.\n",
        "- 데이터 전처리를 위해 불필요한 열을 삭제하는 기술을 습득한다.\n",
        "- RandomForestClassifier 모델을 활용하여 데이터의 특성 중요도를 파악하는 방법을 이해한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. pandas를 이용해 csv 파일 읽어오기\n",
        "[문제 1]  \n",
        "train.csv 파일을 train 변수로 읽어오세요.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd    \n",
        "\n",
        "train = pd.read_csv('___')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'train')\n",
        "@check_safety\n",
        "def check(\n",
        "    user_train: pd.DataFrame,\n",
        "):\n",
        "    c_point1 = hasattr(user_train, 'tail')\n",
        "\n",
        "    if c_point1 :\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "`pd.read_csv('파일경로/파일명')` 를 활용해 보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "import pandas as pd  \n",
        "\n",
        "train = pd.read_csv('train.csv')  \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. 결측값 제거 전후 데이터 확인\n",
        "\n",
        "데이터 전처리는 머신러닝 모델링 과정에서 매우 중요한 단계입니다.   \n",
        "이 과정에서 데이터의 품질을 개선하고, 분석에 적합한 형태로 변환합니다.   \n",
        "결측값 처리는 이러한 전처리 과정 중 하나로, 우리가 사용할 데이터셋에 결측값이 있는지 확인해야 합니다.   \n",
        "결측값은 모델링 단계에서 문제를 일으킬 수 있기 때문입니다.  \n",
        "\n",
        "결측값을 처리하는 방법에는 다양하게 있지만, 가장 간단하면서도 효과적인 방법 중 하나는 결측값이 포함된 행(row)을 제거하는 것입니다.  \n",
        "그래서 먼저 'train'에서 결측값을 확인하고, 이를 제거하는 과정을 진행해보겠습니다.\n",
        "\n",
        "[문제 2]\n",
        "- `isnull().sum()` 함수를 사용하여 각 열에 몇 개의 결측치가 존재하는지 확인해 보세요.\n",
        "- `dropna()` 함수를 사용하여 결측값이 포함된 행을 제거해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(\"-----결측값 제거 전-----\", train.___().___())\n",
        "\n",
        "train_dropna = train.___()\n",
        "\n",
        "display(\"-----결측값 제거 후-----\", train_dropna.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'train_dropna')\n",
        "@check_safety\n",
        "def check(\n",
        "    user_answer:pd.DataFrame,\n",
        "    train_dropna_shape:tuple\n",
        "):\n",
        "    c_point1 = user_answer.shape == train_dropna_shape\n",
        "    \n",
        "    if c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "check(train_dropna, (3836, 16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "train 데이터프레임(DataFrame) 내의 결측값 수를 확인합니다.   \n",
        "`train.isnull().sum()`은 각 열(column)에 대해 결측값의 수를 계산하고, 그 결과를 표시합니다.   \n",
        "이를 통해 데이터프레임 내 어떤 열에 결측값이 얼마나 많이 있는지를 확인할 수 있습니다.\n",
        "\n",
        "결측값이 제거된 새로운 데이터프레임인 train_dropna를 생성합니다.   \n",
        "`dropna()` 함수는 데이터프레임에서 결측값이 있는 행(row)을 제거하고, 결측값이 없는 행만을 남겨둡니다.\n",
        "\n",
        "train_dropna 데이터프레임 내의 결측값 수를 다시 확인합니다.   \n",
        "결측값이 모두 제거되었으므로 이제 해당 데이터프레임은 결측값을 포함하지 않아야 합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "display(\"-----결측값 제거 전-----\", train.isnull().sum())\n",
        "\n",
        "train_dropna = train.dropna()\n",
        "\n",
        "display(\"-----결측값 제거 후-----\", train_dropna.isnull().sum())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.독립변수 종속변수 설정\n",
        "\n",
        "데이터 분석과 모델링에 들어가기 전에, 우리는 독립 변수와 종속 변수를 명확하게 구분해야 합니다.   \n",
        "독립 변수는 우리가 예측을 위해 사용하는 입력 데이터로, 종속 변수는 우리가 예측하려는 대상입니다.\n",
        "\n",
        "이 프로젝트의 목표는 'target' 값을 예측하는 것입니다.   \n",
        "따라서 종속 변수 y는 'target' 열의 값으로 설정합니다.\n",
        "\n",
        "반면, 독립 변수 X는 'target'과 'ID'를 제외한 나머지 모든 열의 값들로 설정합니다.   \n",
        "여기서 'ID' 열은 각 행을 식별하는 데 사용되며, 이 값은 우리의 예측 작업에 영향을 주지 않기 때문에 제외합니다.\n",
        "\n",
        "이제 pandas의 drop 함수를 사용하여 필요한 독립변수와 종속변수를 추출하고, 이들을 각각 x와 y라는 두 개의 별도 데이터 프레임으로 분리해보겠습니다\n",
        "\n",
        "\n",
        "[문제 3]  \n",
        "데이터프레임에서 열(Column)을 제거하기 위해 `drop()`함수를 사용해 봅시다.  \n",
        "`drop()`함수를 사용하여 예측에 사용하지 않는 `ID` 칼럼(column)과 예측할 `target` 피처(feature)를 제거해주세요.  \n",
        "`axis = 1` 로 설정 하여 해당 피처(feature)를 제거해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = train_dropna.___(['___','___'], axis = ___)\n",
        "y = train_dropna['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'x')\n",
        "@check_safety\n",
        "def check(\n",
        "    user_answer:pd.DataFrame,\n",
        "    train_dropna_shape:int\n",
        "):\n",
        "    c_point1 = len(user_answer.columns) == train_dropna_shape\n",
        "    \n",
        "    if c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "check(x, 14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "예측에 사용하지 않는 ID 칼럼(column)과 예측할 target피처(feature)를 제거한 후 x 변수에 할당해 주고,  \n",
        "예측할 변수 target를 y 변수에 할당해 주었습니다.  \n",
        "`.drop()` 함수를 사용하면 특정 피처(feature)를 제거할 수 있습니다.  \n",
        "`axis = 1` 로 설정을 하면 해당 피처(feature)를 제거할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "```python\n",
        "x = train_dropna.drop(['ID','target'], axis = 1)\n",
        "y = train_dropna['target']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4.train_test_split을 사용한 (train / validation) 분할\n",
        "\n",
        "우리는 전체 데이터셋을 학습용 데이터와 검증용 데이터로 나눠야 합니다.   \n",
        "이렇게 하면 우리의 모델이 새로운, 이전에 보지 못한 데이터에 대해 얼마나 잘 예측하는지를 평가할 수 있습니다.\n",
        "\n",
        "[문제 4]  \n",
        "scikit-learn 라이브러리에서 제공하는 `train_test_split` 함수를 사용하여 데이터를 훈련 세트와 검증 세트로 나누어 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ___\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = ___(x, y, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'x_valid', 'y_valid')\n",
        "@check_safety\n",
        "def check(\n",
        "        user_answer_x : str,\n",
        "        user_answer_y : str,\n",
        "):\n",
        "    c_point0 = hasattr(user_answer_x, 'head')\n",
        "    c_point1 = hasattr(user_answer_y, 'head')\n",
        "\n",
        "    if c_point0 and c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(x_valid,y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "\n",
        "이번 스테이지에서는 간단한 모델링을 진행할 예정입니다.   \n",
        "모델을 만들기 전에, 만든 모델이 의미있는지를 확인하는 것이 중요합니다.   \n",
        "그러나 단순히 주어진 데이터로 train 데이터를 학습시켜서 test 데이터로 예측을 수행하면,   \n",
        "모델이 적합한지 판단하기 어렵습니다.   \n",
        "또한, 머신러닝 모델을 train 데이터셋으로만 학습시킨 후 test 데이터를 예측하면,   \n",
        "모델의 성능이 예상보다 낮게 나올 수 있습니다.   \n",
        "이러한 현상을 보통 '과적합(Overfitting)'이라고 합니다.   \n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/88147986/150300564-6cd074fa-6fb0-4c2c-8d12-2e7d9730cbc4.png\">\n",
        "                                 이미지 출처 : educative.io\n",
        "\n",
        "'과적합(Overfitting)' 문제를 해결하기 위해서는 **\"train 데이터에서 validation 데이터를 분리\"시켜서 모델의 적합성을 확인**해야 합니다.   \n",
        "그렇게 함으로써 모델이 너무 학습 데이터에 과적합(Overfitting)되는 경우를 방지할 수 있습니다.   \n",
        "과적합이 발생하면, 모델이 학습한 데이터에 대해서는 높은 성능을 보일 수 있지만 **새로운 데이터에 대해서는 성능이 현저히 떨어지는 문제**가 발생할 수 있습니다.\n",
        "\n",
        "--- \n",
        "**[train 데이터에서 validation 데이터를 분리]**\n",
        "\n",
        "<img width=\"523\" alt=\"image\" src=\"https://user-images.githubusercontent.com/75363345/225542990-ef846e56-fca4-485e-aa37-d473f43fa152.png\">\n",
        "\n",
        "위의 그림과 같이, 기존에 train과 test로 나누어져 있던 데이터 셋에서 train 데이터를 일정 비율의 train/validation으로 분리합니다.   \n",
        "이렇게 분리한 train 데이터 중 일부를 학습에 사용하고,   \n",
        "나머지를 validation 데이터로 사용하여 모델의 성능을 평가합니다.\n",
        "\n",
        "데이터 분석 경진대회에서는 test 데이터셋에 대한 정답 정보가 없기 때문에,   \n",
        "일반적으로 validation 데이터셋을 사용하여 모델을 검증합니다.   \n",
        "이를 통해 모델이 적절하게 학습되었는지 확인하고, 일반화 성능을 평가할 수 있습니다.  \n",
        "\n",
        "---\n",
        "\n",
        "이제 train 데이터 셋에서 validation 데이터 셋을 분리해보겠습니다.\n",
        "분리하는 방법은 scikit-learn 패키지의 model_selection 모듈 안에 있는 train_test_split 함수를 사용하면 간편합니다.  \n",
        "이 함수는 x와 y 데이터를 인자로 받고, test_size 옵션을 이용하여 비율(0~1 사이)을 조절할 수 있습니다.  \n",
        "또한 random_state 옵션을 이용하여 실행할 때마다 동일한 결과를 얻을 수 있습니다.  \n",
        "함수를 사용하면 x_train, x_valid, y_train, y_valid와 같이 학습 데이터셋과 검증 데이터셋으로 데이터를 분할할 수 있습니다.  \n",
        "\n",
        "```\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=비율(0~1 사이), random_state=숫자)\n",
        "```\n",
        "\n",
        "- x: 학습에 사용되는 독립 변수 데이터   \n",
        "- y: 예측하고자 하는 종속 변수 데이터   \n",
        "- test_size: 테스트용 데이터 개수를 지정 (1보다 작은 실수를 기재할 경우, 비율을 나타냄)\n",
        "- train_size: 학습용 데이터의 개수를 지정 (1보다 작은 실수를 기재할 경우, 비율을 나타냄)  \n",
        "  \\* train_size와 test_size는 둘 중 하나만 기재해도 됨\n",
        "- random_state: 난수 시드 (동일한 데이터셋을 얻기 위한 파라미터)\n",
        "\n",
        "---\n",
        "위에서 설정한 독립변수는 X에, 종속변수는 y 자리에 할당했습니다.   \n",
        "train 데이터 셋에서 검증용 데이터로 30%를 사용할 것이기 때문에 0.3을 test_size로 설정해 주었고,   \n",
        "random_state는 42로 설정을 해 주었습니다.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 분할된 (train / validation) 데이터의 shape 확인  \n",
        "\n",
        "train과 valid를 7:3의 비율로 분리하였습니다.   \n",
        "올바르게 분리가 되었는지 확인해 보기 위해 `shape`을 확인해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train 데이터 사이즈 (2685, 14)\n",
            "X_valid 데이터 사이즈 (1151, 14)\n",
            " \n",
            "y_train 데이터 사이즈 (2685,)\n",
            "y_valid 데이터 사이즈 (1151,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train 데이터 사이즈', x_train.shape)\n",
        "print('X_valid 데이터 사이즈', x_valid.shape)\n",
        "print(\" \")\n",
        "print('y_train 데이터 사이즈', y_train.shape)\n",
        "print('y_valid 데이터 사이즈', y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#checkcode\n",
        "#empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. LabelEncoder를 사용한 범주형 데이터 인코딩\n",
        "\n",
        "머신러닝 모델은 대부분 숫자형 데이터를 입력으로 받습니다.   \n",
        "따라서 문자열이나 카테고리 데이터는 모델링에 사용하기 전에 숫자로 변환해야 합니다.   \n",
        "이러한 변환을 수행하는 방법 중 하나는 레이블 인코딩(Label Encoding)입니다.\n",
        "\n",
        "레이블 인코딩은 각 고유한 문자열 값에 대해 고유한 정수를 할당하는 방식입니다.   \n",
        "Scikit-learn의 LabelEncoder 클래스를 사용하면 이 작업을 쉽게 수행할 수 있습니다.\n",
        "\n",
        "[문제 6]\n",
        "- `sklearn.preprocessing` 모듈에서 `LabelEncoder`라는 클래스를 불러와 보세요.\n",
        "- 현재 열(column)의 데이터타입이 `object` 라면 아래 셀을 실행합니다.\n",
        "- `LabelEncoder` 객체를 생성해 주세요.\n",
        "- `fit_transform` 메서드를 사용하여 `x_train` 데이터프레임(DataFrame)의 현재 열을 숫자로 변환해 주세요.\n",
        "- `unique` 함수를 사용하여 현재 열에 대해 모든 고유한 범주를 반복합니다.\n",
        "- `transform` 메서드를 사용하여 x_train 데이터와 동일한 Label Encoding을 적용해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.___ import ___\n",
        "import numpy as np\n",
        "\n",
        "# 범주형 열에 대한 LabelEncoder를 적용하여 문자열을 숫자로 변환\n",
        "for col in x_train.columns:\n",
        "    if x_train[col].dtype == '___':\n",
        "        \n",
        "        le = ___()\n",
        "        x_train[col] = le.___(x_train[col]) # 학습 데이터에 대해 LabelEncoder를 적용하고 변환\n",
        "\n",
        "        # 검증 데이터에 대한 레이블이 학습 데이터에 없는 경우에 대비하여 클래스 확장\n",
        "        for label in np.___(x_valid[col]):\n",
        "            if label not in le.classes_:\n",
        "                le.classes_ = np.append(le.classes_, label)\n",
        "        x_valid[col] = le.___(x_valid[col]) # 검증 데이터에 대해 LabelEncoder를 적용하고 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'x_train')\n",
        "@check_safety\n",
        "def check(\n",
        "    train_df: pd.DataFrame,\n",
        "    val_df: pd.DataFrame,\n",
        "    dtype: str,\n",
        "    num: int\n",
        "):\n",
        "    \n",
        "    train_object_cols = train_df.select_dtypes(include=dtype).columns\n",
        "    valid_object_cols = val_df.select_dtypes(include=dtype).columns\n",
        "\n",
        "    c_point0 = len(train_object_cols) == num\n",
        "    c_point1 = len(valid_object_cols) == num\n",
        "\n",
        "    if c_point0 and c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(x_train, x_valid, 'object', 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "\n",
        "범주형(categorical) 데이터를 처리하기 위해 Label Encoding을 수행하는 과정을 나타냅니다.   \n",
        "Label Encoding은 범주형 데이터를 숫자로 변환하여 머신러닝 모델이 이해할 수 있도록 하는 과정입니다.\n",
        "\n",
        "- scikit-learn 라이브러리에서 `LabelEncoder` 클래스를 불러옵니다. 이 클래스는 범주형 데이터를 숫자로 인코딩하는 데 사용됩니다.\n",
        "- `x_train` 데이터프레임의 모든 열(column)에 대한 반복문을 시작합니다.\n",
        "- 현재 열이 데이터타입이 'object'인지 확인합니다.   \n",
        "'object' 데이터타입은 주로 문자열을 나타내며, 범주형 데이터의 일반적인 형태입니다. 따라서 범주형 열에 대해서만 Label Encoding을 수행합니다.  \n",
        "- `LabelEncoder` 객체를 생성합니다. 이 객체는 범주형 열을 숫자로 변환하는 데 사용됩니다.\n",
        "- `fit_transform` 메서드를 사용하여 `x_train` 데이터프레임의 현재 열을 숫자로 변환합니다. Label Encoder는 각 범주에 대해 고유한 숫자를 할당합니다.\n",
        "- `x_valid` 데이터프레임의 현재 열에 대해 모든 고유한 범주를 반복합니다.\n",
        "- 현재 범주(label)가 Label Encoder의 클래스에 없는 경우\n",
        "- Label Encoder의 클래스에 새로운 범주(label)를 추가합니다.\n",
        "- `x_valid` 데이터프레임의 현재 열을 변환하여 훈련 데이터와 동일한 Label Encoding을 적용합니다.\n",
        "\n",
        "이렇게 하면 훈련 데이터와 검증 데이터 모두에 대해 동일한 Label Encoding이 적용되어 범주형 데이터가 숫자로 변환됩니다.   \n",
        "이후 이러한 숫자 데이터를 머신러닝 모델에 입력으로 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# 범주형 열에 대한 LabelEncoder를 적용하여 문자열을 숫자로 변환\n",
        "for col in x_train.columns:\n",
        "    if x_train[col].dtype == 'object':\n",
        "        \n",
        "        le = LabelEncoder()\n",
        "        x_train[col] = le.fit_transform(x_train[col])  # 학습 데이터에 대해 LabelEncoder를 적용하고 변환\n",
        "        \n",
        "        # 검증 데이터에 대한 레이블이 학습 데이터에 없는 경우에 대비하여 클래스 확장\n",
        "        for label in np.unique(x_valid[col]):\n",
        "            if label not in le.classes_:\n",
        "                le.classes_ = np.append(le.classes_, label)\n",
        "        \n",
        "        x_valid[col] = le.transform(x_valid[col])  # 검증 데이터에 대해 LabelEncoder를 적용하고 변환\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7.RandomForestClassifier 모델을 사용한 valid 데이터 예측 및 평가\n",
        "\n",
        "이제 우리는 머신러닝 모델을 생성하고 학습시킬 준비가 되었습니다.   \n",
        "이번에 사용할 모델은 랜덤 포레스트입니다. 랜덤 포레스트는 여러 개의 결정 트리를 활용하여 결과를 예측하는 알고리즘으로,   \n",
        "각각의 트리가 독립적으로 학습하기 때문에 과적합 문제를 상당히 잘 방지합니다.\n",
        "\n",
        "[문제 7]\n",
        "- `sklearn.ensemble` 모듈에서 `RandomForestClassifier` 클래스를 불러와주세요.\n",
        "- `RandomForestClassifier` 모델을 생성하여 rf_classifier 변수에 할당해 주세요.\n",
        "- 학습 데이터인 `x_train`과 `y_train`을 사용하여 학습시켜주세요.\n",
        "- 학습된 모델을 사용하여 검증 데이터인 `x_valid`에 대한 예측을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.___ import RandomForestClassifier\n",
        "\n",
        "# RandomForestClassifier 모델 생성 및 학습\n",
        "rf_classifier = ____(random_state=42)\n",
        "rf_classifier.fit(___, ___)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(___)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'rf_classifier','y_pred')\n",
        "@check_safety\n",
        "def check(\n",
        "    user_answer_model:str,\n",
        "    user_answer_predict:float,\n",
        "    user_answer_test:float\n",
        "):\n",
        "    \n",
        "    check_p0 = str(type(user_answer_model)) == \"<class 'sklearn.ensemble._forest.RandomForestClassifier'>\"\n",
        "    check_p1 = len(user_answer_predict) == len(user_answer_test)\n",
        "\n",
        "    if check_p0 and check_p1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(rf_classifier,y_pred,x_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "RandomForest 모델은 **여러 개의 의사결정트리(Decision Tree)를 조합**하여 만든 앙상블(Ensemble) 모델 중 하나입니다.   \n",
        "각각의 의사결정트리는 데이터의 일부를 랜덤으로 선택하여 학습하며, 이를 통해 일반화 성능을 높입니다. 또한, RandomForest 모델은 분류와 회귀 문제에 모두 적용 가능합니다.\n",
        "\n",
        "RandomForestClassifier의 주요 특징과 작동 방식은 다음과 같습니다:\n",
        "\n",
        "- 앙상블 학습: RandomForestClassifier는 여러 개의 결정 트리(Decision Tree) 모델을 조합하여 높은 분류 성능을 달성하는 앙상블 학습 방법을 사용합니다. 이때, 각 결정 트리는 서로 독립적으로 학습하며 예측을 수행합니다.\n",
        "\n",
        "- 무작위성: 랜덤 포레스트는 무작위성을 도입하여 각 트리의 다양성을 높입니다. 무작위성은 다음과 같은 방법으로 적용됩니다:\n",
        "\n",
        "    - 부트스트랩 샘플링: 각 트리는 원본 데이터에서 중복을 허용한 무작위 샘플을 생성하여 학습합니다.\n",
        "    - 무작위 특성 선택: 각 노드에서 특성을 선택할 때 전체 특성 중 일부만 고려합니다. 이렇게 하면 각 트리가 서로 다른 특성을 고려하게 되며, 다양한 관점에서 학습합니다.\n",
        "    \n",
        "- 부스팅  : 랜덤 포레스트는 다수의 결정 트리를 조합하여 예측을 수행하므로 과적합(Overfitting) 경향이 낮습니다. 또한, 이러한 특성으로 인해 노이즈에 강하며 안정적인 성능을 제공합니다.\n",
        "\n",
        "- 중요도 측정: RandomForestClassifier는 각 특성의 중요도를 측정할 수 있으며, 어떤 특성이 분류 결정에 가장 중요한 역할을 하는지 확인할 수 있습니다. 이를 통해 특성 선택과 모델 해석에 도움이 됩니다.\n",
        "\n",
        "- 예측 및 분류: 모델이 학습되면 새로운 데이터 포인트에 대한 분류를 예측할 수 있습니다. 각 결정 트리의 예측 결과를 다수결 투표 또는 평균을 통해 최종 예측 결과를 도출합니다.\n",
        "\n",
        "RandomForestClassifier는 다양한 분류 문제에 적용할 수 있으며, 데이터의 특성과 크기에 따라 다양한 하이퍼파라미터를 조정하여 최적의 성능을 얻을 수 있습니다. 또한, scikit-learn과 같은 머신러닝 라이브러리에서 쉽게 사용할 수 있습니다.\n",
        "\n",
        "![Random Forest_도식_직접제작 (1)](https://user-images.githubusercontent.com/75363345/234730997-483cb8f0-f9c8-4358-a168-ce7af0ccefc7.png)\n",
        "\n",
        "해당 코드에 대한 설명은 다음과 같습니다.  \n",
        "sklearn.model_selection 모듈에서 train_test_split 함수를 가져옵니다.  \n",
        "sklearn.ensemble 모듈에서 RandomForestClassifier 클래스를 가져옵니다.  \n",
        "RandomForestClassifier 모델을 생성하고, random_state 매개변수를 설정하여 결과 재현성을 보장합니다.  \n",
        "RandomForestClassifier 모델을 학습 데이터인 x_train과 y_train을 사용하여 학습시킵니다.  \n",
        "학습된 모델을 사용하여 검증 데이터인 x_valid를 입력으로 하여 예측을 수행하고, 예측 결과를 y_pred 변수에 저장합니다.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# RandomForestClassifier 모델 생성 및 학습\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(x_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(x_valid)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8.RandomForest 모델의 Macro F1 스코어 계산 및 출력\n",
        "\n",
        "모델의 성능을 평가하는 여러 가지 방법 중 하나는 F1 스코어를 계산하는 것입니다.   \n",
        "F1 스코어는 정밀도와 재현율의 조화 평균으로, 모델이 양성 클래스를 얼마나 잘 예측했는지에 대한 척도입니다.   \n",
        "특히, Macro F1 스코어는 다중 클래스 분류 문제에서 각 클래스별로 F1 스코어를 계산하고 이들의 평균값을 구함으로써 전체적인 모델 성능을 측정합니다.   \n",
        "이번에는 sklearn 라이브러리의 f1_score 함수를 사용하여 우리의 예측 결과에 대한 Macro F1 스코어를 계산해보겠습니다.\n",
        "\n",
        "[문제 8]\n",
        "- `sklearn.metrics` 모듈에서 `f1_score` 함수를 가져와보세요.\n",
        "- `f1_score` 함수를 사용하여 실제 레이블인 검증 데이터의 목표값 `y_valid`와 모델의 예측 결과 `y_pred`를 비교하여 Macro F1 스코어를 계산해보세요.  \n",
        "- `average` 매개변수를 `macro`로 설정하여 Macro F1 스코어를 계산하고, 이 값을 macro_f1 변수에 저장해보세요.  \n",
        "계산된 Macro F1 스코어를 화면에 출력합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 스코어: 0.7872447301227592\n"
          ]
        }
      ],
      "source": [
        "from sklearn.___ import f1_score\n",
        "\n",
        "# Macro F1 스코어 계산\n",
        "macro_f1 = f1_score(y_valid, ___, average='___')\n",
        "print(\"Macro F1 스코어:\", macro_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'macro_f1')\n",
        "@check_safety\n",
        "def check(\n",
        "    macro_f1: float,\n",
        "    macro_f1_check: float\n",
        "):\n",
        "    c_point1 = macro_f1 == macro_f1_check\n",
        "\n",
        "    if c_point1 :\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(f1_score(y_valid, y_pred, average='macro'), f1_score(y_valid, y_pred, average=None).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "\n",
        "Macro F1 스코어는 분류(Classification) 모델의 성능을 측정하는 지표 중 하나입니다.   \n",
        "이 스코어는 모든 클래스에 대한 F1 스코어를 계산하고, 그 평균을 구한 것입니다.   \n",
        "F1 스코어는 정밀도(Precision)와 재현율(Recall)의 조화 평균입니다.\n",
        "\n",
        "F1 스코어는 다음과 같이 정의됩니다:\n",
        "\n",
        "> F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "Precision은 모델이 Positive로 예측한 것 중에서 실제로 Positive인 비율을 나타냅니다.  \n",
        "Recall은 실제로 Positive인 것 중에서 모델이 Positive로 예측한 비율을 나타냅니다.  \n",
        "Macro F1 스코어는 각 클래스별로 F1 스코어를 계산하고, 이를 클래스 수만큼 더한 후 클래스 수로 나눈 값입니다.   \n",
        "이를 통해 각 클래스의 중요도가 동등하게 고려됩니다.\n",
        "\n",
        "예를 들어, 다중 클래스 분류 모델에서 세 가지 클래스 (A, B, C)에 대한 Macro F1 스코어를 계산한다고 가정해보겠습니다.   \n",
        "이 경우, 각 클래스별로 F1 스코어를 계산하고, 이를 더한 후 클래스 수인 3으로 나누어 Macro F1 스코어를 구합니다.   \n",
        "이것은 모든 클래스에 대한 분류 성능을 평균적으로 나타내는 지표로 사용됩니다.\n",
        "\n",
        "---\n",
        "\n",
        "#### 결과 해석\n",
        "\n",
        "Macro F1 스코어는 0에서 1 사이의 값을 가집니다.   \n",
        "값이 1에 가까울수록 모델의 성능이 좋다는 것을 의미하며, 반대로 0에 가까울수록 모델의 성능이 나쁘다는 것을 의미합니다.\n",
        "\n",
        "여기서 Macro F1 스코어가 약 0.787로, 이는 전반적으로 모델의 성능이 꽤 좋은 편임을 나타냅니다.  \n",
        "Macro F1 스코어는 각 클래스별로 동일한 가중치를 적용하여 평균을 구하므로, 불균형한 클래스 분포를 고려했다고 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Macro F1 스코어 계산\n",
        "macro_f1 = f1_score(y_valid, y_pred, average='macro')\n",
        "print(\"Macro F1 스코어:\", macro_f1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9.데이터 분할 및 train/valid 데이터 준비\n",
        "\n",
        "[문제 9]\n",
        "- train.csv 파일을 train 변수로 읽어오세요.\n",
        "- 독립변수 x에는 target 을 제외한 나머지 모든 열의 값들로 설정해 주세요.\n",
        "- 종속변수 y에는 target 열의 값으로 설정해 주세요.\n",
        "- 독립변수 x, 종속변수 y 데이터를 훈련 세트와 검증 세트로 나누어 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.read_csv('___')\n",
        "\n",
        "x = train.___([___], axis = ___)\n",
        "y = train[___]\n",
        "\n",
        "train_data, ___, ___, valid_targets = ___(___, ___, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'train_data', 'valid_data')\n",
        "@check_safety\n",
        "def check(\n",
        "        user_answer_x : str,\n",
        "        user_answer_y : str,\n",
        "):\n",
        "    c_point0 = hasattr(user_answer_x, 'head')\n",
        "    c_point1 = hasattr(user_answer_y, 'head')\n",
        "\n",
        "    if c_point0 and c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(train_data,valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "`drop()` 함수를 사용하면 특정 칼럼을 제거할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "x = train.drop(['target'], axis = 1)\n",
        "y = train['target']\n",
        "\n",
        "train_data, valid_data, train_targets, valid_targets = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10.결측값 보간(Imputer)을 통한 데이터 전처리\n",
        "\n",
        "이전 단계에서는 결측치가 있는 행을 모두 제거하여 데이터를 정리했습니다.  \n",
        "그러나 이 방법은 중요한 정보를 잃을 수 있으며, 데이터셋의 크기를 줄일 수 있습니다.   \n",
        "따라서 이번에는 다른 접근 방식을 사용하여 결측치를 처리해보려 합니다.\n",
        "\n",
        "결측치 보간(Imputation)은 누락된 값을 추정하는 과정입니다.   \n",
        "이번 스텝에서는 'SimpleImputer'라는 sklearn의 유틸리티를 사용하여 결측치 보간을 진행하려 합니다.   \n",
        "SimpleImputer는 기본적으로 평균, 중앙값, `최빈값` 등 다양한 전략으로 결측치를 채울 수 있습니다.\n",
        "\n",
        "여기서 우리는 'most_frequent' 전략을 사용할 것입니다.   \n",
        "즉, 각 특성(열)에서 가장 자주 등장하는 값으로 해당 특성의 결측치들을 대체합니다.   \n",
        "여기서 선택한 특성은 'occupation'과 'workclass'로, 이들 열에 있는 모든 결측값들이 각각의 `최빈값`으로 대체될 것입니다.\n",
        "\n",
        "[문제 10]  \n",
        "- `sklearn.impute` 모듈에서 결측치 처리를 위한 `SimpleImputer` 클래스를 가져오세요.    \n",
        "- `SimpleImputer` 객체를 생성하고, 결측치를 처리할 때 사용할 전략(strategy)을 `most_frequent`로 설정해주세요.  \n",
        "- 학습 데이터셋인 `train_data`의 'occupation'과 'workclass' 열에 대해 결측치를 `최빈값`으로 채우기 위해 `imputer` 객체의 `fit_transform` 메서드를 사용합니다.   \n",
        "- 검증 데이터셋인 `valid_data`의 'occupation'과 'workclass' 열에 대해 결측치를 `최빈값`으로 채우기 위해 `imputer` 객체의 `transform` 메서드를 사용합니다.   \n",
        "\n",
        "이렇게 함으로써 'occupation'과 'workclass' 열의 결측치가 처리되고, 결측치가 있는 행들이 더 이상 없어집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import ___\n",
        "\n",
        "# SimpleImputer를 사용하여 결측치를 최빈값으로 보간\n",
        "imputer = SimpleImputer(strategy='___')\n",
        "\n",
        "train_data[['occupation','workclass']] = imputer.___(___[['occupation','workclass']])\n",
        "valid_data[['occupation','workclass']] = imputer.___(___[['occupation','workclass']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals())\n",
        "@check_safety\n",
        "def check(\n",
        "    df: pd.DataFrame,\n",
        "    col1: str,\n",
        "    col2: str,\n",
        "    zero: int\n",
        "):\n",
        "    c_point0 = df.isnull().sum()[col1] == zero\n",
        "    c_point1 = df.isnull().sum()[col2] == zero\n",
        "\n",
        "    if c_point0 and c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(train_data, 'occupation', 'workclass', 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "`SimpleImputer`는 sklearn의 impute 모듈에 포함된 클래스로, 결측치를 다루는 데 사용됩니다.   \n",
        "이 클래스는 각 특성(열)의 결측값을 특정 값으로 대체하는 역할을 합니다.\n",
        "\n",
        "`most_frequent` 전략은 이름에서 알 수 있듯이, 해당 특성에서 가장 자주 발생하는 값으로 결측치를 대체합니다.   \n",
        "즉, 각 열의 최빈값(mode)를 찾아 그 값으로 결측치를 채웁니다.\n",
        "\n",
        "예를 들어 'occupation'이라는 카테고리 변수에서 'Teacher', 'Engineer', 'Doctor' 등 여러 직업들이 있고,   \n",
        "'Teacher'가 가장 많다면 `most_frequent` 전략을 사용하면 모든 결측치가 'Teacher'로 대체됩니다.\n",
        "\n",
        "이 방법은 주로 범주형 데이터에 사용되며, 숫자형 데이터에 대해서도 사용할 수 있지만 평균(mean) 또는 중앙값(median) 전략을 적용하는 것이 일반적입니다.  \n",
        "데이터의 분포를 고려하여 결측치를 대체하므로 해당 열의 특성을 유지하면서 결측치를 채울 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "```python\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# SimpleImputer를 사용하여 결측치를 최빈값으로 보간\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "train_data[['occupation','workclass']] = imputer.fit_transform(train_data[['occupation','workclass']])\n",
        "valid_data[['occupation','workclass']] = imputer.transform(valid_data[['occupation','workclass']])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11. 불필요한 열 제거를 통한 데이터 전처리\n",
        "\n",
        "데이터 전처리 과정에서는 불필요한 특성을 제거하는 것이 중요합니다.   \n",
        "이는 모델의 성능을 향상시키고, 학습 시간을 줄이며, 오버피팅(과적합)을 방지하는 데 도움이 됩니다. \n",
        "\n",
        "우리의 데이터셋에서 'ID', 'native.country', 그리고 'education' 열은 다음과 같은 이유로 제거할 예정입니다.\n",
        "\n",
        "- 'ID': 이 특성은 각 샘플의 고유 식별자로, 모델 학습에 도움이 되지 않습니다. 실제로 ID는 종종 잡음(noise)으로 작용하여 모델의 성능을 저하시킬 수 있습니다.\n",
        "- 'native.country': 이 특성은 결측치가 있는 행의 개수가 적어서 제거합니다. 결측치를 보간하는 대신에 해당 데이터를 제거하면 모델의 복잡도를 줄일 수 있습니다.\n",
        "- 'education': 우리 데이터셋에는 이미 'education.num'라는 칼럼이 있으며, 이 칼럼은 'education' 칼럼과 동일한 정보를 담고 있습니다.   \n",
        "중복된 정보를 가진 두 개의 특성이 있다면 한 개만 유지하고 다른 하나를 삭제하는 것이 좋습니다.\n",
        "\n",
        "[문제 11]\n",
        "\n",
        "`'native.country', 'ID', 'education'` 열을 각각 `train_data`과 `valid_data` 데이터프레임에서 삭제하여 이들 열을 제외한 나머지 열만 남게 해주세요.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_data = train_data.___(['ID','native.country','education'], axis = ___)\n",
        "valid_data = valid_data.___(['ID','native.country','education'], axis = ___)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals())\n",
        "@check_safety\n",
        "def check(\n",
        "    df: pd.DataFrame,\n",
        "    col1: str,\n",
        "    col2: str,\n",
        "    col3: str,\n",
        "):\n",
        "    c_point0 = col1 not in df.columns\n",
        "    c_point1 = col2 not in df.columns\n",
        "    c_point2 = col3 not in df.columns\n",
        "\n",
        "    if c_point0 and c_point1 and c_point2:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(train_data, 'ID', 'native.country', 'education')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "train_data = train_data.drop(['ID','native.country','education'], axis = 1)\n",
        "valid_data = valid_data.drop(['ID','native.country','education'], axis = 1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 12. LabelEncoder를 사용한 범주형 데이터 인코딩\n",
        "\n",
        "- sklearn 패키지에서 LabelEncoder라는 클래스를 불러와 보세요.\n",
        "- 현재 열의 데이터타입이 문자형이 라면 아래 셀을 실행합니다.\n",
        "- train_data 데이터프레임에 LabelEncoder를 적용하고 변환시켜주세요.\n",
        "- 현재 열에 대해 모든 고유한 범주를 반복합니다.\n",
        "- valid_data 데이터프레임에 train_data 데이터와 동일한 Label Encoding을 적용해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.___ import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# 범주형 열에 대한 LabelEncoder를 적용하여 문자열을 숫자로 변환\n",
        "for col in train_data.columns:\n",
        "    if train_data[col].___ == '___':\n",
        "        \n",
        "        le = LabelEncoder()\n",
        "        train_data[col] = le.___(train_data[___])  # 학습 데이터에 대해 LabelEncoder를 적용하고 변환\n",
        "        \n",
        "        # 검증 데이터에 대한 레이블이 학습 데이터에 없는 경우에 대비하여 클래스 확장\n",
        "        for label in ___.___(valid_data[col]):\n",
        "            if label not in le.classes_:\n",
        "                le.classes_ = np.append(le.classes_, label)\n",
        "        \n",
        "        valid_data[col] = le.___(___[col])  # 검증 데이터에 대해 LabelEncoder를 적용하고 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'train_data')\n",
        "@check_safety\n",
        "def check(\n",
        "    train_df: pd.DataFrame,\n",
        "    val_df: pd.DataFrame,\n",
        "    dtype: str,\n",
        "    num: int\n",
        "):\n",
        "    \n",
        "    train_object_cols = train_df.select_dtypes(include=dtype).columns\n",
        "    valid_object_cols = val_df.select_dtypes(include=dtype).columns\n",
        "\n",
        "    c_point0 = len(train_object_cols) == num\n",
        "    c_point1 = len(valid_object_cols) == num\n",
        "\n",
        "    if c_point0 and c_point1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(train_data, valid_data, 'object', 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "- `sklearn.preprocessing` 모듈에서 `LabelEncoder`라는 클래스를 불러올 수 있습니다.\n",
        "- `.dtype` 메소드를 이용하면 데이터 타입을 확인할 수 있습니다.\n",
        "- 현재 열의 데이터타입이 `object` 라면 아래 셀을 실행합니다.\n",
        "- `fit_transform` 메서드를 사용하면 LabelEncoder를 적용할 수 있습니다.\n",
        "- `np.unique` 함수를 사용하면 현재 열에 대해 모든 고유한 범주를 추출할 수 있습니다.\n",
        "- `transform` 메서드를 사용하여 valid_data 데이터에 Label Encoding을 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution.\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# 범주형 열에 대한 LabelEncoder를 적용하여 문자열을 숫자로 변환\n",
        "for col in train_data.columns:\n",
        "    if train_data[col].dtype == 'object':\n",
        "        \n",
        "        le = LabelEncoder()\n",
        "        train_data[col] = le.fit_transform(train_data[col])  # 학습 데이터에 대해 LabelEncoder를 적용하고 변환\n",
        "        \n",
        "        # 검증 데이터에 대한 레이블이 학습 데이터에 없는 경우에 대비하여 클래스 확장\n",
        "        for label in np.unique(valid_data[col]):\n",
        "            if label not in le.classes_:\n",
        "                le.classes_ = np.append(le.classes_, label)\n",
        "        \n",
        "        valid_data[col] = le.transform(valid_data[col])  # 검증 데이터에 대해 LabelEncoder를 적용하고 변환\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13.RandomForestClassifier 모델을 활용한 데이터 분석 및 성능 평가\n",
        "\n",
        "[문제 13]\n",
        "- sklearn 패키지에서 RandomForestClassifier 클래스를 불러와주세요.\n",
        "- sklearn 패키지에서 f1_score 클래스를 불러와주세요.\n",
        "- RandomForestClassifier 모델을 생성해 주세요. random_state 는 42로 설정하여 재현성을 보장해주세요.\n",
        "- 학습 데이터를 사용하여 학습시켜주세요.\n",
        "- 학습된 모델을 사용하여 검증 데이터에 대한 예측을 수행합니다.\n",
        "- f1_score 함수를 사용하여 실제 레이블인 검증 데이터의 목표값과 모델의 예측 결과를 비교하여 Macro F1 스코어를 계산해보세요. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.___ import RandomForestClassifier\n",
        "from sklearn.___ import f1_score\n",
        "\n",
        "# RandomForestClassifier 모델 생성 및 학습\n",
        "rf_classifier = RandomForestClassifier(___=42)\n",
        "rf_classifier.fit(___, ___)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(___)\n",
        "\n",
        "# Macro F1 스코어 계산\n",
        "macro_f1 = f1_score(___, ___, average='macro')\n",
        "print(\"Macro F1 스코어:\", macro_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'macro_f1')\n",
        "@check_safety\n",
        "def check(\n",
        "    macro_f1: float,\n",
        "    macro_f1_check: float\n",
        "):\n",
        "    c_point1 = macro_f1 == macro_f1_check\n",
        "\n",
        "    if c_point1 :\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(f1_score(valid_targets, y_pred, average='macro'), f1_score(valid_targets, y_pred, average=None).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "\n",
        "---\n",
        "\n",
        "#### 결과 해석\n",
        "\n",
        "이전에 결측치가 존재하는 행을 제거한 후 RandomForestClassifier 모델의 Macro F1 스코어는 약 0.78였습니다.   \n",
        "이번에는 결측치를 보간한 후 다시 모델을 학습시키고 성능을 평가해보았습니다.\n",
        "\n",
        "결과적으로, 결측치를 'most_frequent' 전략으로 보간한 후의 모델 성능은 Macro F1 스코어가 0.8을 넘어서는 결과를 보여주었습니다.   \n",
        "이것은 단순히 결측치를 제거하는 것보다 해당 값을 보간하여 사용하는 것이 우리의 모델 성능 향상에 더 도움이 되었다는 것을 의미합니다.\n",
        "\n",
        "즉, 이 경우에서는 데이터 손실을 최소화하면서도 유용한 정보를 유지하기 위해 결측치를 보간하는 방법이 더 좋은 결과를 가져왔습니다.   \n",
        "그러나 항상 이런 전략이 더 나은 결과를 가져오는 것은 아니며,   \n",
        "사용하는 데이터셋과 문제에 따라 적절한 결측치 처리 방법이 달라질 수 있음을 기억해야 합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "- `sklearn.ensemble` 모듈에서 `RandomForestClassifier` 클래스를 불러올 수 있습니다.\n",
        "- `sklearn.metrics` 모듈에서 `f1_score` 클래스를 불러올 수 있습니다.\n",
        "- `RandomForestClassifier` 모델을 생성하여 rf_classifier 변수에 할당해 주세요.\n",
        "- 학습 데이터는 train_data, valid_data 입니다.\n",
        "- 검증 데이터는 train_targets 입니다.\n",
        "- 검증 데이터의 목표값은 valid_targets, 모델의 예측 결과는 y_pred 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# RandomForestClassifier 모델 생성 및 학습\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(train_data, train_targets)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(valid_data)\n",
        "\n",
        "# Macro F1 스코어 계산\n",
        "macro_f1 = f1_score(valid_targets, y_pred, average='macro')\n",
        "print(\"Macro F1 스코어:\", macro_f1)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14.랜덤 포레스트 모델의 특성 중요도 시각화\n",
        "\n",
        "머신러닝 모델을 구축하고 학습한 후에는, 어떤 특성들이 예측 결과에 가장 큰 영향을 미치는지 이해하는 것이 중요합니다.   \n",
        "이를 `특성 중요도(feature importance)`라고 하며, 이를 통해 모델의 해석력을 높일 수 있습니다.\n",
        "\n",
        "랜덤 포레스트(Random Forest)와 같은 앙상블 모델은 각 특성의 중요도를 쉽게 계산할 수 있는 장점이 있습니다.   \n",
        "RandomForestClassifier 클래스의 `feature_importances_` 속성은 학습된 모델에서 각 특성의 중요도를 나타내는 값들을 반환합니다.\n",
        "\n",
        "[문제 14]        \n",
        "랜덤 포레스트 분류기(RandomForestClassifier) 모델을 사용하여 학습한 후, 각 특성(Feature)의 중요도를 시각화해보겠습니다.\n",
        "\n",
        "- `rf_classifier` 모델에서 계산한 특성 중요도 `feature_importances_` 값을 `data` 변수에,     \n",
        "`x_train` 데이터프레임의 열 이름(`columns`)을 `index` 변수에 할당하여 하는 `Series` 객체를 생성해주세요. \n",
        "\n",
        "- `sort_values` 함수를 사용하여 중요도 값들을 내림차순으로 정렬해보세요.    \n",
        "이렇게 하면 중요도가 높은 순서대로 데이터프레임이 정렬됩니다.\n",
        "\n",
        "- seaborn 라이브러리의 `barplot` 함수를 사용하여 중요도가 높은 특성 순으로 막대 그래프를 생성합니다.   \n",
        "`x`에는 중요도 값(`feature_series`)을, `y`에는 특성의 이름(열의 이름)을 지정합니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# 각 특성(Feature)의 중요도를 시각화할 시리즈(Series) 생성\n",
        "feature_series = pd.___(data=rf_classifier.___, index=train_data.___)\n",
        "\n",
        "# 중요도 값 기준으로 내림차순 정렬\n",
        "feature_series = feature_series.___(ascending=False)\n",
        "\n",
        "# 중요도를 막대 그래프로 표현하기 위해 seaborn의 barplot 함수 사용\n",
        "# x에는 중요도 값(feature_series)을, y에는 특성의 이름(열의 이름)을 설정\n",
        "sns.___(x=___, y=feature_series.index)\n",
        "\n",
        "# 그래프 출력\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#checkcode\n",
        "ensure_vals(globals(), 'feature_series')\n",
        "@check_safety\n",
        "def check(\n",
        "    importance_series: pd.Series,\n",
        "    col1: str,\n",
        "    col2: str,\n",
        "    col3: str\n",
        "):\n",
        "    c_point1 = col1 not in importance_series.index\n",
        "    c_point2 = col2 not in importance_series.index\n",
        "    c_point3 = col3 not in importance_series.index\n",
        "\n",
        "    if c_point1 and c_point2 and c_point3 :\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "check(feature_series, 'education', 'ID', 'native.country')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inst.\n",
        "해당 코드는 랜덤 포레스트 분류기(RandomForestClassifier) 모델을 사용하여 학습한 후, 각 특성(Feature)의 중요도를 시각화하는 과정을 나타냅니다.\n",
        "\n",
        "> `rf_classifier.feature_importances_`\n",
        "\n",
        "랜덤 포레스트 모델에서 학습한 각 특성의 중요도를 나타내는 속성입니다.   \n",
        "모델이 예측을 수행하는 데 어떤 특성이 얼마나 중요한 역할을 하는지를 나타내는 값들로 구성되어 있습니다.\n",
        "\n",
        "> `pd.Series(data=rf_classifier.feature_importances_, index=x_train.columns)`\n",
        "\n",
        "`rf_classifier.feature_importances_` 값을 기반으로 데이터프레임의 형태로 중요도 값을 저장합니다.   \n",
        "여기서 `x_train.columns`은 특성의 이름(열의 이름)을 나타내며, 이를 인덱스로 설정하여 각 특성에 대한 중요도를 레이블링합니다.\n",
        "\n",
        "> `feature_series.sort_values(ascending=False)`\n",
        "\n",
        "중요도 값들을 내림차순으로 정렬합니다.   \n",
        "이렇게 하면 중요도가 높은 순서대로 데이터프레임이 정렬됩니다.\n",
        "\n",
        "> `sns.barplot(x=feature_series, y=feature_series.index)`\n",
        "\n",
        "seaborn 라이브러리의 `barplot` 함수를 사용하여 중요도가 높은 특성 순으로 막대 그래프를 생성합니다.   \n",
        "`x`에는 중요도 값(`feature_series`)을, `y`에는 특성의 이름(열의 이름)을 지정합니다.   \n",
        "이렇게 하면 각 특성의 중요도를 시각적으로 파악할 수 있습니다.\n",
        "\n",
        "이 코드를 통해 랜덤 포레스트 모델에서 각 특성의 상대적인 중요도를 시각화하여 어떤 특성이 모델에 영향을 미치는지 확인할 수 있습니다.   \n",
        "이 정보는 특성 선택이나 모델 해석에 유용하게 활용될 수 있습니다.\n",
        "\n",
        "---\n",
        "\n",
        "#### 결과 해석\n",
        "\n",
        "피처 중요도(Feature Importance)를 시각화한 결과를 보면, 'fnlwgt', 'age', 그리고 'education.num'이 모델 예측에 가장 큰 영향을 미치는 특성들임을 알 수 있습니다.   \n",
        "이 세 가지 특성은 바(Bar) 차트에서 가장 높은 값을 가지며, 이는 각각의 특성이 우리의 랜덤 포레스트 분류기 모델에서 결과 예측에 중요한 역할을 하는 것을 의미합니다.\n",
        "\n",
        "'fnlwgt'는 사람들의 인구 통계학적 가중치를 나타내며, 이 값이 높다는 것은 해당 인구 집단이 전체 데이터셋에서 차지하는 비율이 크다는 것을 의미합니다.   \n",
        "따라서 'fnlwgt'가 높게 나온 것은 해당 특성이 결과 예측에 많은 정보를 제공한다고 볼 수 있습니다.\n",
        "\n",
        "그 다음으로 'age'와 'education.num'도 중요한 역할을 하는데, 이들은 각각 사람의 나이와 교육 수준(연수)를 나타냅니다.   \n",
        "나이와 교육 수준은 일반적으로 사람들의 직업 선택과 소득 등에 크게 영향을 미칠 수 있으므로, 이러한 결과가 나온 것은 상당히 합리적입니다.\n",
        "\n",
        "반면에 바 차트 하단에서 볼 수 있는 'sex'와 'race'는 비교적 낮은 중요도 값을 가지고 있습니다.   \n",
        "즉, 우리 모델에서 성별과 인종 정보가 소득 예측에 크게 기여하지 않았다는 것입니다.\n",
        "\n",
        "하지만 주의할 점은, 이러한 해석이 데이터 자체나 실제 현실 문제에 대해 어떤 결론을 내릴 수 있다는 의미가 아니라 오직 우리가 구축한 랜덤 포레스트 모델 내에서만 유효하다는 점입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hint.\n",
        "empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solution\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "# 각 특성(Feature)의 중요도를 시각화할 시리즈(Series) 생성\n",
        "feature_series = pd.Series(data=rf_classifier.feature_importances_, index=train_data.columns)\n",
        "\n",
        "# 중요도 값 기준으로 내림차순 정렬\n",
        "feature_series = feature_series.sort_values(ascending=False)\n",
        "\n",
        "# 중요도를 막대 그래프로 표현하기 위해 seaborn의 barplot 함수 사용\n",
        "# x에는 중요도 값(feature_series)을, y에는 특성의 이름(열의 이름)을 설정\n",
        "sns.barplot(x=feature_series, y=feature_series.index)\n",
        "\n",
        "# 그래프 출력\n",
        "plt.show()\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
